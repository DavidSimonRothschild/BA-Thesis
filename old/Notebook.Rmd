---
title: "R Notebook Analysis"
subtitle: Template
output:
  html_document:
    df_print: paged
---

# Library

```{r}
library(readtext)
library(quanteda)
library(quanteda.textplots)
library(quanteda.textmodels)
library(quanteda.textstats)
library(tidyverse)
library(topicmodels)
library(stm)
library(clue)
```


# Import
```{r}
RLP_AfD <- readtext(paste0("AfD WP18"),stringsAsFactors = FALSE)
```

# Corpus

```{r}
rlp_afd_c <- corpus(RLP_AfD, 
                    text_field = "text")
```

# Tokenization and removing of stop Words

```{r}
rlp_afd_t <- tokens(rlp_afd_c,
                    what = c("word"),
                    include_docvars = TRUE,
                    ngrams = 1L,
                    remove_numbers = TRUE, 
                    remove_punct = TRUE,
                    remove_symbols = TRUE, 
                    remove_hyphens = TRUE
)

rlp_afd_t <- tokens(rlp_afd_t, remove_punct = TRUE, remove_numbers = TRUE) %>% 
  tokens_remove(pattern = stopwords("de", source = "marimo")) %>% 
  tokens_keep(pattern = "^[\\p{script=Latn}]+$", valuetype = "regex")
# remove Stop Words German

rlp_afd_t <- tokens_remove(rlp_afd_t, "\\p{Z}", valuetype = "regex")

```

DFM and remove of specific words
```{r}
rlp_afd_d <- dfm(rlp_afd_t)

rlp_afd_d <- dfm_remove(rlp_afd_d, c("kleine Anfrage", "bitte", "frage", "landtag", "abgefragten","landesreguerung", "druck", "drucksach*", "dr","jan","bollinger", "a", "ggf", "kleine","wahlperiode","abgeordnet*"))

```


Top Words
```{r}

topfeatures(rlp_afd_d, 50)

top_words <-
  topfeatures(rlp_afd_d, 20) %>% 
  data.frame(word = names(.),
             freq = .,
             row.names = c())

freq_tokens <-
  ggplot(top_words, 
         aes(x=reorder(word, freq), y=freq)) +
  geom_col() + 
  coord_flip() +
  theme_minimal() +
  ggtitle("Most frequent tokens") 

freq_tokens
```

Word Cloud

```{r}
library(wordcloud)

quanteda.textplots::textplot_wordcloud(rlp_afd_d,max_words = 100)
```

stm / lda

```{r}
dfm_afd_rlp <- 
  rlp_afd_d %>% 
  dfm_trim(., sparsity = 0.999) %>% 
  convert(., to = "stm")

k = 5

stm_model <- 
  stm(dfm_afd_rlp$documents, 
      dfm_afd_rlp$vocab, 
      K = k, # this is the number of topics
      data = NULL, 
      init.type = "LDA") 

```

topic  modelling / LDA

```{r}
if(!require("topicmodels")) {install.packages("topicmodels"); library("topicmodels")}
if(!require("ldatuning")) {install.packages("ldatuning"); library("ldatuning")}

anzahl.themen <- 10
dfm2topicmodels <- convert(rlp_afd_d, to = "topicmodels")
lda.modell <- LDA(dfm2topicmodels, anzahl.themen)

lda_df <- as.data.frame(terms(lda.modell, 10))
```

Wordfish

```{r}
tmod_wf <- textmodel_wordfish(rlp_afd_d, dir = c(6, 5))
summary(tmod_wf)

textplot_scale1d(tmod_wf, margin = "features", highlighted = c("migration"))

tmca <- textmodel_ca(rlp_afd_d)

textplot_scale1d (tmca)

```

popdictR

```{r}
library(popdictR)

p <- summary(run_popdict(rlp_afd_c))
sum(p$dict_gruendl_2020)
```

